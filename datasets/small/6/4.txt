Nieco ponad pó³ dekady temu badaczami zajmuj¹cymi siê psychologi¹ spo³eczn¹ wstrz¹sn¹³ skandal: po akademickim donosie studentów na swojego profesora wszczête zosta³o (nie bez przeszkód) dochodzenie w kwestii potencjalnego fa³szowania wyników przez Diederika Stapela. Stapel by³ w tym momencie gwiazd¹ psychologii spo³ecznej, publikuj¹c liczne swoje badania w magazynie Science, a tak¿e wiod¹cych periodykach psychologicznych. Gdy postêpowanie dobieg³o koñca, jego kariera by³a ju¿ w gruzach, jego prace – na wylocie (do dzisiaj wycofano ich ponad 50, czyni¹c Stapela jednym z niechlubnych liderów rankingu retrakcji), a spo³ecznoœæ akademicka w szoku.

Stapelowi przez lata k³amanie uchodzi³o p³azem dziêki nieuzasadnionej ³atwowiernoœci kolegów i kole¿anek po fachu, którzy do zaskakuj¹cych wyników Holendra podchodzili bez normalnego zazwyczaj sceptycyzmu. By³oby jednak nieuczciwym stwierdzenie, ¿e tylko jego wyniki unika³y dog³êbnej krytyki i oceny – literatura psychologiczna z ostatnich dekad usiana jest badaniami, które nie tylko nie przetrwa³y próby czasu, ale w dodatku trudno wyjaœniæ, dlaczego zosta³y w ogóle opublikowane. Byæ mo¿e jednak skala fa³szerstwa Stapela by³a wstrz¹sem potrzebnym temu polu nauki: nie powinno byæ zatem zaskoczeniem, ¿e to w psychologii w³aœnie bardzo aktywny jest ruch domagaj¹cy siê badañ replikuj¹cych stare odkrycia, które wszyscy bierzemy na wiarê, chocia¿ mo¿e nie powinniœmy, domagaj¹cy siê te¿, aby nowe badania prowadzone by³y w oparcie o protoko³y rejestrowane przez zbieraniem danych (ang. registered reports).

Upadek Stapela by³ niezwykle publiczny – do tego stopnia, ¿e to, co normalnie by³oby maleñk¹ aferk¹ znan¹ tylko kilku specjalistom, trafi³o pod strzechy nie tylko innych naukowców, ale te¿ laików. I mo¿na by pomyœleæ, ¿e jego historia jest solidn¹ lekcj¹ dla ka¿dego, komu przez myœl przesz³o kiedykolwiek, ¿e mo¿eby podci¹gn¹æ te dane, mo¿eby wywaliæ dwa czy trzy punkty pomiarowe, które wprowadzaj¹ za du¿o szumu do sk¹d in¹d eleganckich wyników. A ju¿ zw³aszcza ¿e tak¹ lekcj¹ jest dla badaczy w tej samej dziedzinie, którzy powinni chyba zrozumieæ, ¿e teraz ca³y œwiat patrzy im na rêce.

Dlatego pewnym zaskoczeniem dla mnie – a podejrzewam, ¿e i dla wielu innych osób – by³o, gdy na pocz¹tku 2017 roku zaczê³o siê robiæ robiæ gor¹co wokó³ kolejnej gwiazdy psychologii (tym razem amerykañskiej), profesora na Uniwersytecie Cornella Briana Wansinka.

Kim jest Brian Wansink?

Bardziej mo¿e w³aœciwe by³oby to pytanie zadane w czasie przesz³ym: kim by³ Wansink, zanim œwiat zacz¹³ mu siê waliæ na g³owê pó³tora roku temu? Wansink nie pojawi³ siê bowiem znik¹d: kariera akademicka tego 58-latka siêga wczesnych lat 90’. Jego badania skupia³y siê na badaniu tego, w jaki sposób ludzie podejmuj¹ decyzje – w du¿ej mierze w kontekœcie ¿ywienia. Znany jest ze swoich badañ na przyk³ad nad tym, jaki wp³yw na nasze ¿ywienie maj¹ rozmiary porcji: z odkrycia, ¿e popcorn w czasie filmu bêdziemy jeœæ tak d³ugo, a¿ siêgniemy dna miski, niezale¿nie od apetytu, albo ¿e zamówienie deseru w restauracji zale¿y od granej w niej muzyki.

W 2007 roku Wansink otrzyma³ najcenniejszego z Nobli – Ig Nobla – za badania z zastosowaniem misek do zupy bez dna. W tym doœwiadczeniu Wansink chcia³ zademonstrowaæ, jak nasze postrzeganie rozmiaru porcji wp³ywa na to, ile w rzeczywistoœci jemy. Uczestnicy badania jedli zupê z niewielkich misek. Czêœæ z nich mia³a miski normalne i jeœli chcieli jeœæ wiêcej, musieli prosiæ o dolewkê. Czêœæ zaœ mia³a miski, które przez dno by³y uzupe³niane zup¹ w takim tempie, w jakim by³a ona zjadana. Wansink pokaza³, ¿e osoby zmuszone do proszenia o kolejne porcje jad³y mniej. Jest to jedno z najbardziej znanych badañ Wansinka (zapewne tylko po czeœci dziêki nagrodzie) – i jedno z wielu, których wnioski stanê³y pod znakiem zapytania na skutek póŸniejszej afery.

W 2006 roku Wansink opublikowa³ ksi¹¿kê popularnonaukow¹ Beztroskie jedzenie, dlaczego jemy wiêcej ni¿ byœmy chcieli, która podsumowywa³a ca³okszta³t jego badañ i by³a kombinacj¹ manifestu i poradnika samo-pomocy (ksi¹¿kê wci¹¿ mo¿na tu i ówdzie nabyæ, linków nie podajê – mo¿ecie sobie oszczêdziæ 50 zeta). W latach 2007-2009 Wansink doradza³ amerykañskiemu rz¹dowi w kwestii dietetycznych wytycznych i programu MyPyramid.gov. W 2014 wyda³ kolejn¹ ksi¹¿kê Slim by Design.

Autor, rz¹dowy doradca, badacz z ponad setk¹ publikacji na koncie, które cytowane by³y ponad 20 tysiêcy razy, oraz z imponuj¹cym indeksem Hirscha na poziomie ponad 70 – do listopada 2016 roku ca³a kariera Wansinka wydawa³a siê byæ pasmem powodzeñ. Wtedy uwagê kilku badaczy zwróci³ z pozoru nieszkodliwy, niewinny post, który Wansink opublikowa³ na prowadzonym przez siebie blogu.

Studentka, która nie odmawia³a

21listopada 2016 Brian Wansink upubliczni³ na swoim blogu wpis, w którym wyjaœnia³, ¿e p-hacking to nie to samo co analiza eksploracyjna danych. Stwierdzenie, które byæ mo¿e w jakimœ kontekœcie jest prawdziwe – nie by³ to jednak kontekst tego wpisu. Wansink t³umaczy bowiem dalej, ¿e czasem, gdy hipoteza nie znajduje poparcia w danych, to trzeba siê przyjrzeæ, czy byæ mo¿e popiera j¹ tylko jakaœ ich czêœæ – zdaniem Wansinka takie postêpowania nie oznacza, ¿e hipoteza ulega zmianie, chocia¿ wyraŸnie jej ulega. Co tu du¿o wiêcej mówiæ. Wansink wyrazi³ te¿ swoj¹ opiniê na temat problemów, jakich doœwiadczaj¹ m³odzi badacze bêd¹cy pod presjê, ¿eby publikowaæ, jeœli chc¹ gdzieœ w akademii zajœæ. Aby zilustrowaæ te dwa problemy – analizy danych oraz problemów m³odych badaczy – Wansink przytoczy³ przyk³ad swojej studentki, Ozge Sigirci. Sigirci by³a doktorantk¹ z Turcji, która mia³a w laboratorium Wansinka odbyæ krótki sta¿. W trakcie jej pobytu Wansink zaproponowa³, ¿eby spróbowa³a przeanalizowaæ dane zebrane w czasie badania przeprowadzonego wczeœniej przez jego grupê, w którym nie uda³o im siê potwierdziæ pierwotnej hipotezy. Wansink mia³ pomys³ na to, jakie hipotezy mo¿na tymi danymi te¿ przetestowaæ, ignoruj¹c zupe³nie to, ¿e wymyœlanie hipotezy po zebraniu danych, jest wbrew jakimkolwiek naukowym praktykom. W ka¿dym bowiem wystarczaj¹co bogatym zbiorze danych da siê odkryæ jakieœ zwi¹zki, które wyskakuj¹ nieco ponad szum.

Sirgici jednak nie tylko nie kwestionowa³a tej rady, ale pos³ucha³a zalecenia i wziê³a siê za przeczesywanie danych – wyniki tego przeczesywania zaskutkowa³y co najmniej czterema publikacjami.

Wpis Wansinka zwróci³ jednak uwagê trzech badaczy, Tima van der Zee i Nicka Browna z Holandii oraz Jordana Anayi ze Stanów. Poruszeni opisanymi przez Wansinka szkodliwymi praktykami, postanowili przeanalizowaæ powtórnie dane, na których oparte by³y badania. Skontaktowali siê z Wansinkiem wskazuj¹c na listê nieœcis³oœci w tych publikacjach – Wansink szybko przesta³ odpowiadaæ na maile, gdy badacze wyjaœnili, ¿e chcieliby otrzymaæ dostêp do pierwotnych danych.

Poznajcie data thugs

Oryginalni krytycy Wansinka zostali przez portal Retraction Watch ochrzczeni ukutym przez Jamesa Heathersa mianem data thugs, które nie ma niestety ¿adnego odpowiednika w jêzyku polskim, a nazywanie ich danowymi zbirami jakoœ mi nie pasuje. Nazwê tê przez ostatnie pó³tora roku zaczêto stosowaæ na okreœlenie badaczy, który analizuj¹c danych z publikacji naukowych odkrywaj¹ ró¿ne machlojki oryginalnych autorów (Heathersowi i Brownowi nale¿y siê tytu³ pierwszych data thugs).

Wracaj¹c do prac Wansinka: pod nieobecnoœæ oryginalnych danych, które pozwoli³yby na powtórn¹ analizê i potwierdzenie jego wyników, van der Zee, Anaya i Brown przeprowadzili takie analizy, jakie siê da³o – a ich wyniki opublikowali w BMC Nutrition, jednym z pism, w których ukaza³y siê oryginalne wyniki Wansinka.

Nie jest bowiem tak, ¿e pewnych nieœcis³oœci – ¿eby nie powiedzieæ wprost, oczywistych b³êdów – nie da siê wykryæ nawet bez dostêpu do oryginalnych danych.

Po pierwsze zatem, krytycy skupili siê na nieœcis³oœciach w opisie metodologii pracy. Poniewa¿ teoretycznie wszystkie cztery publikacje, które analizowali, zosta³y napisane w oparciu o ten sam zbiór danych, opis tych danych powinien byæ w nich taki sam. Jak siê z tego wstêpu mo¿ecie jednak spodziewaæ – wcale taki nie by³ (w podlinkowanej analizie z BMC Nutrition rozbie¿noœci pokazuje Tabela 2). Problematyczne jest nie tylko to, ¿e te same dane ró¿ni¹ siê pomiêdzy publikacjami, ale te¿ na przyk³ad to, ¿e suma wszystkich testowanych grup nie jest taka sama jak przytoczony gdzie indziej rozmiar ca³ej próby. Piêciolatek zrozumie, ¿e jeœli wartoœci po dwóch stronach znaku równoœci nie s¹ identyczne, to ten znak równoœci mija siê z celem. Profesor na Uniwersytecie Cornella jakoœ ten szkopu³ pomin¹³.

Po drugie, dla pewnych rodzajów danych istniej¹ testy statystyczne pozwalaj¹ce sprawdziæ, czy œrednia wartoœæ dla próby jest matematycznie mo¿liwa, bior¹c pod uwagê projekt badania. Brown i Heathers, opracowali taki test kilka lat temu i w pracy opisuj¹cej jego dzia³anie podaj¹ na wstêpie ³adny przyk³ad, który poni¿ej upraszczam (matma jest prosta, ale jak nie chcecie, to wy³uszczony fragment mo¿na po prostu przeskoczyæ):

Proszê sobie wyobraziæ, ¿e mamy 28 osobow¹ grupê badanych (N=28), którzy odpowiadaj¹ na pytanie, w którym odpowiedzi udziela siê na siedmiopunktowej skali (takich jak: ca³kiem siê zgadzam, trochê siê zgadzam, ciut siê zgadzam, ani siê zgadzam ani nie zgadzam itd., punktowane od 1 do 7). W wynikach doœwiadczenia badacze podaj¹, ¿e œredni wynik to 5.19 +/- 1.34.

Abstrahuj¹c od tego, na jakie pytanie odpowiadali badani i jak bardzo zaskakuj¹cy lub nie jest wynik 5.19, jest on niemo¿liwy z technicznego punktu widzenia. Jeœli mamy 28 uczestników, których odpowiedziami by³y de facto liczby ca³kowite z zakresu 1 do 7, to suma ich wyników musi byæ liczb¹ ca³kowit¹ z zakresu 28 (28*1) i 196 (28*7).

5,19*28 to 145,32. Poniewa¿ 5,19 to œrednia uzyskana przez podzielenie sumy dla wszystkich uczestników przez 28, t¹ sum¹ nie mog³o byæ 145,32: musia³o to byæ albo 145 albo 146.

Jednak jeœli podzielimy któryœ z tych wyników przez 28 i zaokr¹glimy do drugiego miejsca po przecinku, to w ¿adnych z tych wypadków nie otrzymamy 5,19 – œrednia dla 28 uczestników ze 145 to 5,178571 – zaokr¹glone daje 5,18. Œrednia ze 146 to 5,21428, które zaokr¹glone daje 5,21. Czyli ¿aden wynik z tego doœwiadczenia nie móg³ daæ œredniej 5,19, która znalaz³a siê potem w wynikach.

Co mo¿e byæ wyjaœnieniem? S¹ wyjaœnienia niewinne – b³¹d typograficzny lub przypadkowe niew³¹czenie czyjegoœ wyniku do badania. S¹ te¿ wyjaœnienia znacznie bardziej niepokoj¹ce: na przyk³ad fabrykacja danych.

Innymi problemami w pracach by³a nieœcis³oœæ definicji, ró¿ne rozmiary grup, a nawet sposób pomiaru (doœwiadczenie polega³o na obserwowaniu, ile spo¿ywali klienci pizzeri – olbrzymie znaczenie mia³oby na przyk³ad to, czy ostatni niedojedzony kawa³ek pizzy liczy siê jako zjedzony czy nie, albo to, w którym momencie sprawdzano, ile kawa³ków pizzy mog³o zostaæ na talerzu).

M¹drzejsza sto³ówka

Podczas gdy analiza van der Zee, Anayi i Browna skupi³a siê na tzw. pizza study, inny badacz, Eric Robinson z Liverpoolu, mia³ podobne w¹tpliwoœci dotycz¹ce innej serii badañ Wansinka nad sposobem promowania zdrowego ¿ywienia na szkolnych sto³ówkach, stosuj¹c techniki behawioralne ze szko³y Richarda Thalera. Wansink na przyk³ad twierdzi³, ¿e nadawanie zdrowemu jedzeniu bardziej przyjemnych nazw spowoduje, ¿e uczniowe bêd¹ je chêtniej jedli. Robinsona zaniepokoi³o to, jak pozytywne by³y wyniki programu – bo chocia¿ byæ mo¿e nie by³oby nieoczekiwane, ¿e taka strategia pomog³aby zmieniæ nawyki ¿ywieniowe ma³ej liczbie uczniów, by³o jednak zaskoczeniem, ¿e media taktykê opiewa³y jak nadejœcie mesjasza.

Robinson przeanalizowa³ prace Wansinka, które by³y podstaw¹ programu Smarter Lunchrooms. Zrobi³ to pod k¹tem analizy spójnoœci wyników, ale tak¿e aby sprawdziæ, czy doniesienia medialne dok³adnie odzwierciedla³y wyniki publikacji naukowych. W kolejnych publikacjach Robinson identyfikowa³ problemy podobne do tych, których doszukali siê krytycy innych prac: niespójnoœci metodologiczne w obrêbie poszczególnych prac (jedna z publikacji podawa³a na przyk³ad trzy ró¿ne rozmiary tej samej próby), niespójnoœci w sposobie prezentowania wyników (jedna z publikacji podawa³a dok³adnie przeciwne wnioski w abstrakcie i w g³ównym tekœcie publikacji), niespójnoœæ w opisie uczestników badania (jedna z prac opisuje 8-11-latków w sposób zarezerwowany zazwyczaj dla dzieci w wieku przedszkolnym – póŸniej okaza³o siê, ¿e w istocie w tym badaniu opisywano badania na 3-5-latkach).

Robinson odkry³ te¿, ¿e liczne prace, nawet jeœli uzyskane wyniki s¹ doœæ skromne, opisuj¹ ostateczne wnioski stosuj¹c znacznie bardziej obiecuj¹cy (¿eby nie powiedzieæ: obfity) jêzyk, de facto zak³amuj¹c rzeczywistoœæ ukryt¹ w numerycznych wynikach doœwiadczeñ.

Czego nie powiedz¹ wam liczby, powiedz¹ wam emaile

Opisywane powy¿ej w¹tpliwoœci œwiat³o dzienne ujrza³y w pierwszej po³owie 2017 roku – na blogu van der Zee, i pocz¹tkowo w formie preprintów. Praca w BMC Nutrition opublikowana zosta³a dopiero w lipcu 2017 – i tak szybko, jak na akademickie standardy, ale wci¹¿ cztery miesi¹ce póŸniej ni¿ pierwsze próby upublicznienia problemów z pracami Wansinka. Jednak publikacje, preprinty i blogi dalekie s¹ od bardziej powszechnego nag³oœnienia k³opotów z tymi publikacjami – co jest nie bez znaczenia bior¹c pod uwagê na przyk³ad skalê eksperymentu z programem Smarter Lunchrooms (fundowanego z pieniêdzy federalnych za ponad 22 miliony dolarów w blisko 30 tysi¹cach amerykañskich szkó³).

Na szczêœcie jednak temat podchwyci³y szybko publiczne media: magazyn New York ju¿ w lutym opublikowa³ tekst opisuj¹ce sagê badañ nad jedzeniem pizzy, nazywaj¹c je w tytule artyku³u trefnymi. Miesi¹ce póŸniej nowej perspektywy te¿ doda³ BuzzFeed, który poprzez FOIA dosta³ dostêp do korespondencji mailowej Wansinka. Okaza³o siê, ¿e w odpowiedzi na tê publiczn¹ krytykê Wansink wys³a³ list do kilkudziesiêciu kolegów, broni¹c swoich publikacji, wyjaœniaj¹c, ¿e problemy wynika³y z „drobnych” k³opotów takich jak brakuj¹ce dane, czy b³êdy w przybli¿eniach, ale tak¿e nazywaj¹c krytykê cyber-znêcaniem.

Krytycy nie ustêpowali – Brown analizuj¹c historyczne prace Wansinka zwróci³ uwagê na liczne przypadki auto-plagiatu, na co Wansink w kolejnym emailu do w³adz uczelni t³umaczy³, ¿e niektóre z tych powtórzeñ by³y usprawiedliwione wag¹ przekazywanej przez nie wiadomoœci (przypomina to trochê stary argument usprawiedliwiaj¹cy plagiat tym, ¿e jest on najwy¿sz¹ formê pochlebstwa). Inne maile pokazuj¹, ¿e Wansink nie by³ w stanie zlokalizowaæ, który z jego wspó³pracowników ma dane bêd¹ce podstawê niektórych z jego badañ.

Znacznie bardziej pogr¹¿a jednak Wansinka korespondencja sprzed 2016 roku – co krok pojawiaj¹ siê w niej opisy tego, jak w „kreatywny” sposób analizowaæ dane, aby uzyskaæ znacz¹cy statystycznie wynik – ten œwiêty Gral nauki, który da³by publikacjê w presti¿owym fachowym piœmie. Wansink przyucza³ Sirgici w tym kierunku jeszcze przed jej przyjazdem do Stanów – obiecuj¹c, ¿e jeœli uda siê jej coœ z danych wydusiæ, to na pewno zaimponuje to reszcie zespo³u, a mo¿e da i jak¹œ pulikacjê.

Zawiód³ badacz, zawiod³o i œrodowisko

Pomimo wywiadów, pomimo sprawdzenia wyników analiz przez niezale¿n¹ firmê, pomimo wycofania siê Wansinka ze œwiat³a jupiterów, lawiny nie da³o siê zatrzymaæ. Cornell wszcz¹³ postêpowanie dyscyplinarne. Pisma, w których publikowane by³y jego prace, zaczê³y siê tym pracom przygl¹daæ na nowo, próbuj¹c zweryfikowaæ ich poprawnoœæ.

Powolutku zaczê³y siê do literatury fachowej s¹czyæ korekty i retrakcje – pierwszy artyku³ wycofano ju¿ w kwietniu 2017 roku. By³o to badanie pokazuj¹ce, jak zawartoœæ etykiet na jedzeniu wp³ywa na ich smak. Ta retrakcja by³a raczej waniliowa – pracê wycofano bowiem „jedynie” za auto-plagiat. Nie jest jednak zaskoczeniem, ¿e praca, która runê³a pierwsza, runê³a przez plagiat, gdy¿ poœród ró¿nych bol¹czek publikacji Wansinka, plagiat jest naj³atwiejszy do udowodnienia. Przed koñcem 2017 wycofano 5, a poprawiono 8 jego artyku³ów.

Od pocz¹tku 2018 do listy do³¹czy³o kolejnych 9 retrakcji. Stopieñ komplikacji tej sagi dobrze ilustruj¹ przejœcia niektórych spoœród tych artyku³ów. Jeden wycofano, poniewa¿, chocia¿ teoretycznie mo¿liwa by³a korekta, okaza³o siê, ¿e poprawka by³aby d³u¿sza ni¿ oryginalny artyku³. Jeden artyku³ wycofano, opublikowano ponownie, i jeszcze raz wycofano. JAMA, której ró¿ne pisma opublikowa³y szeœæ prac Wansinka, wczeœniej w tym roku opublikowa³a do tych artyku³ów noty redakcyjne – rodzaj artyku³u, zwracaj¹cego uwagê czytelników na potencjalny problem z badaniem, zanim do koñca dojdzie postêpowanie uczelniane pokazuj¹ce, czy rzeczywiœcie dosz³o do fa³szerstwa lub innych machloj. W tym samym czasie JAMA zwróci³a siê do Uniwersytetu Cornella o wszczêcie takiego postêpowania

Do wielkiego fina³u dosz³o w ubieg³ym tygodniu. Uniwersytet Cornella og³osi³, ¿e postêpowania zakoñczono i ¿e uczelniane œledztwo ustali³o, ¿e Wansink zachowa³ siê nieetycznie (ang. academic misconduct) poprzez m.in. b³êdne raportowanie wyników, stosowanie w¹tpliwych metod statystycznych, b³êdy w prowadzeniu i archiwizacji dokumentacji badawczej oraz problemy z autorstwem prac (to zapewne dotyczy wszystkich jego auto-plagiatów). Dzieñ wczeœniej JAMA network wycofa³a wszystkie szeœæ artyku³ów, który wczeœniej mia³y noty redakcyjne. Sam Wansink postanowi³ odejœæ z Uniwersytetu Cornella – chocia¿ mo¿na podejrzewaæ, ¿e nie jest to odejœcie nie do koñca niewymuszone.

I mo¿na powiedzieæ, ¿e historia tutaj siê koñczy. Z³oczyñca zosta³ wykryty i ukarany. Literatura naukowa zosta³a poprawiona. Publiczne upokorzenie zosta³o uskutecznione. A jednak niesmak wci¹¿ pozostaje.

Bo – tak jak i w przypadku Diederika Stapela – winnych jest znacznie wiêcej. O ile sk³onny jestem byæ bardziej pob³a¿liwy wobec studentów Wansinka, którym w koñcu ich w³asny mentor mówi³, ¿e manipulacja i oszustwa s¹ ok, o tyle tej samej wymówki nie mog¹ u¿yæ jego bardziej doœwiadczeni wspó³pracownicy, którzy na tych publikacjach byli wspó³autorami. Autorstwo pracy naukowej oznacza bowiem odpowiedzialnoœæ za jej treœæ. Tutaj wychodzi na to, ¿e prezentowany wynik by³ zbyt ciekawy, zbyt seksowny, zbyt niebywa³y i gwarantuj¹cy publikacjê, ¿eby wspó³autorom chcia³o siê dok³adnie przyjrzeæ tym danym. O tyle tej samej wymówki nie mog¹ u¿yæ redaktorzy pism, które te prace opublikowa³y tylko dlatego, ¿e by³y one gwarantem cytowañ. O tyle tej samej wymówki nie mog¹ u¿yæ recenzenci – bo nie ma na œwiecie wymówki na to, ¿e recenzent nie zauwa¿y³, ¿e rozmiar próby ma trzy ró¿ne wartoœci w tej samej pracy! I wreszcie tej samej wymówki nie mog¹ u¿yæ czytelnicy, specjaliœci w tej samej dziedzinie, którzy przez lata czytali, chwalili i cytowali te wyniki, nie kwestionuj¹c ich w najmniejszym nawet stopniu. Czyli ponownie, pomimo pó³ dekady samobiczowania i pracy nad powtarzalnoœci¹ badañ, zawiód³ nie tylko badacz, ale i ca³a akademicka spo³ecznoœæ.